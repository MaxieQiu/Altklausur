《并行体系结构》详细讲解（基于 Felix Wolf 教授讲义）

1. 分类方法（Taxonomies）｜第 3–6 页
并行计算机体系结构可从多个维度分类，最经典的是 Flynn 分类法（Flynn’s classification, 1966），它根据指令流数量（instruction streams）和数据流数量（data streams）划分：
- SISD（Single Instruction, Single Data）：单指令单数据。这是传统单核 CPU 的工作方式，一次只执行一条指令、处理一个数据。属于串行处理。
- SIMD（Single Instruction, Multiple Data）：单指令多数据。多个处理单元同时执行同一条指令，但作用于不同的数据。典型应用包括：向量处理器（vector processors）、多媒体指令扩展（如 Intel 的 SSE/AVX）。适用于数据并行（data parallelism）场景。
- MISD（Multiple Instruction, Single Data）：多指令单数据。理论上存在，但没有商用系统采用此架构，实际意义很小。
- MIMD（Multiple Instruction, Multiple Data）：多指令多数据。每个处理器独立取指、独立操作自己的数据，支持线程级并行（thread-level parallelism）。这是现代多核 CPU、多处理器服务器和集群的主流架构，具有高度灵活性，可运行多个程序或一个程序的多个线程。
此外，GPU 采用一种特殊变体：SIMT（Single Instruction, Multiple Threads）：
- GPU 将线程分组为 warp（通常 32 个线程）。
- 每个 warp 执行同一条指令，但允许分支发散（divergent branching）：部分线程可被禁用（inactive），从而实现逻辑上的独立控制流。
- SIMT 是 SIMD 的泛化，兼顾效率与灵活性。

2. 存储体系结构（Memory Architecture）｜第 7、12–15 页
存储结构决定了处理器如何访问内存，直接影响编程模型和性能。
（1）共享内存系统（Shared-memory systems）
所有处理器通过统一地址空间访问内存。
- UMA（Uniform Memory Access）：
  - 所有 CPU 访问任意内存地址的延迟相同。
  - 通常通过总线（bus）或简单交换网络连接。
  - 优点：编程简单；缺点：扩展性差（通常不超过 1–2 个 CPU 插槽）。
  - 示例：早期多核工作站。
- NUMA（Non-Uniform Memory Access）：
  - 内存按 CPU 分区，每个 CPU 有本地内存（local memory）和远程内存（remote memory）。
  - 访问本地内存快，远程慢。
  - 优点：可扩展性好（支持数十甚至上百核）；缺点：编程需考虑数据局部性。
  - 现代服务器（如 Intel Xeon）普遍采用 NUMA。
（2）分布式内存系统（Distributed-memory systems / Multicomputer）
- 每个节点（node）拥有独立的物理内存，无全局地址空间。
- 节点间通过消息传递（message passing，如 MPI）通信。
- 编程复杂，但可无限扩展，适用于超大规模集群。
（3）混合架构（Hierarchical architecture）
- 现代 HPC 集群典型结构：
  - 节点内：多核 CPU 共享内存（NUMA）。
  - 节点间：通过高速网络（如 InfiniBand）连接，采用分布式内存模型。
- 这种“两级并行”结构兼顾性能与可扩展性。

3. 互连网络（Interconnection Networks）｜第 16–31 页
互连网络负责连接处理器、内存或节点，是并行系统性能的关键。
（1）共享介质网络（Shared-media networks）
- 所有设备共享同一通信通道（如总线）。
- 同一时间只能传输一条消息。
- 采用载波侦听多路访问（CSMA）等机制避免冲突。
- 优点：成本低；缺点：不可扩展，带宽争用严重。
- 应用：早期多处理器系统。
（2）交换式网络（Switched-media networks）
- 每个节点通过独立链路连接到交换机。
- 支持并发通信（多个消息同时传输）。
- 分两类：
a. 集中式交换网络（Centralized switched networks）
- 使用多级交换结构连接所有端点。
- 示例：
  - Crossbar（交叉开关）：任意输入可连任意输出，无阻塞，但硬件复杂度为 O(N²)，仅适用于小规模系统。
  - Omega 网络（Multistage Interconnection Network, MIN）：由多级 2×2 交换开关组成，复杂度 O(N log N)，但有阻塞（不同路径可能冲突）。
  - Fat Tree（胖树）：树形结构，但上层链路带宽更高，保证总带宽均衡。广泛用于现代集群（如 Lichtenberg）。
b. 分布式交换网络（Distributed switched networks）
- 每个节点自带交换功能，形成直接网络（direct network）。
- 拓扑示例：
  - Mesh（网格）：二维或三维网格，节点仅与邻居相连。适合局部通信。
  - Torus（环面）：Mesh 加上“环绕边”，每个维度首尾相连，提升连通性。
  - Dragonfly：高可扩展拓扑，用于超大规模系统（如 Cray 超算）。

4. 异构性与定制化（Heterogeneity & Customization）｜第 8–11 页
（1）异构性（Degree of heterogeneity）
- 同构节点（Homogeneous）：所有计算单元相同（如纯 CPU 集群）。
- 异构节点（Heterogeneous）：包含不同类型处理器：
  - GPU（Graphics Processing Unit）：擅长数据并行，用于 AI/科学计算。
  - FPGA（Field-Programmable Gate Array）：可重构硬件，适合特定算法加速。
  - 神经形态芯片（Neuromorphic）：模拟神经元，低功耗事件驱动。
  - 量子处理器（Quantum）：用于特定指数级问题（如 Shor 算法）。
（2）定制化程度（Degree of customization）
- 商品集群（Commodity clusters）：
  - 使用标准服务器和网络（如以太网）。
  - 成本低，适合通用计算。
  - 示例：Beowulf 集群。
- 定制集群（Custom clusters）：
  - 专用节点 + 专用互连（如定制 InfiniBand）。
  - 针对特定应用优化（如气候模拟、核聚变）。
  - 示例：日本 Fugaku（富岳）超算。

5. 缓存一致性（Cache Coherence）｜第 42–58 页
在共享内存多处理器中，每个 CPU 有私有缓存。若多个缓存同时持有同一内存地址的副本，必须保证一致性（coherence）。
一致性定义（Coherence requirements）：
1. 同一 CPU 的读操作应看到自己最近的写。
2. 不同 CPU 对同一地址的写应被所有 CPU 以相同顺序观察到（写序列化）。
3. 读操作应返回最近的写入值（若无中间写）。
一致性协议类型：
- 侦听协议（Snooping protocol）：
  - 所有缓存通过总线监听内存请求。
  - 写操作时广播无效化（invalidate）或更新（update）消息。
  - 适用于 UMA 系统（如多核 CPU）。
- 目录协议（Directory-based protocol）：
  - 每个内存块有一个目录（directory），记录哪些缓存持有副本。
  - 适用于 NUMA 系统，避免广播开销。
  - 目录可集中或分布（后者更可扩展）。
常见策略：
- 写无效（Write invalidate）：写时使其他副本失效（主流方案）。
- 写更新（Write update）：写时广播新值（带宽消耗大，少用）。
MESI 协议（Modified/Exclusive/Shared/Invalid）｜第 49–56 页
- Modified（M）：本缓存有最新数据，内存无效，其他缓存无副本。
- Exclusive（E）：本缓存有数据，内存一致，其他缓存无副本。
- Shared（S）：多个缓存有副本，内存一致。
- Invalid（I）：缓存行无效。
状态转换通过总线事务（如 Read, Write, Invalidate）触发。
一致性缺失（Coherence misses）｜第 57–58 页
- 真共享缺失（True sharing miss）：因其他 CPU 写入同一变量导致失效。
- 伪共享缺失（False sharing miss）：因其他 CPU 写入同一缓存行中的不同变量导致失效。可通过数据对齐或填充（padding）缓解。

6. 内存一致性模型（Memory Consistency Model）｜第 77–80 页
缓存一致性只保证单地址行为正确，而内存一致性模型（memory consistency model）规定多地址访问的全局顺序。
- 顺序一致性（Sequential Consistency, SC）：
  - 所有操作看起来按某个全局顺序执行，且每个线程的操作顺序不变。
  - 编程直观，但性能差（禁止乱序执行）。
- 宽松一致性模型（Relaxed consistency models）：
  - 允许硬件/编译器重排读写操作以提升性能。
  - 通过同步操作（如锁、屏障）恢复关键顺序。
  - 现代 CPU（x86、ARM）均采用某种宽松模型。
⚠️ 若程序存在数据竞争（data race，即无同步的并发读写），行为未定义。

7. 同步机制（Synchronization）｜第 81–82 页
同步用于协调线程/进程，确保正确性。
- 依赖硬件原子操作（atomic operations）：
  - 如 compare-and-swap（CAS）、load-linked/store-conditional（LL/SC）。
- 同步原语：锁（mutex）、信号量、屏障（barrier）等。
- 在高并发或大规模系统中，同步可能成为性能瓶颈。

8. 实例：Lichtenberg 超级计算机｜第 31–41 页
德国达姆施塔特工业大学的 Lichtenberg II 超算系统：
（1）节点类型
- MPI 节点（630+576 台）：
  - CPU：Intel Cascade Lake（96 核）或 Sapphire Rapids（104 核）
  - 内存：384–512 GB RAM
  - NUMA 域：≥4
- 大内存节点（Big-Mem，5 台）：
  - 最高 6 TB RAM（4×Sapphire Rapids）
- 加速器节点（19 台）：
  - GPU：NVIDIA V100 / A100 / H100
  - 其他：Intel Ponte Vecchio（PVC）、AMD MI300X
（2）互连网络
- InfiniBand HDR100：100 Gb/s（节点到交换机），200 Gb/s（交换机间）
- Fat Tree 拓扑：无阻塞（non-blocking），任意两节点可全带宽通信
（3）冷却与能效
- 高温热水冷却（40–55°C）
- 废热回收用于校园供暖
（4）文件系统
- /home：永久存储，每日备份，配额 50 GB
- /work：临时存储（8 周自动删除），配额 20 TB

9. 总结（Summary）｜第 83 页
并行体系结构全景图：
- 指令/数据流：SISD / SIMD / MISD / MIMD
- 内存：共享（UMA/NUMA/ccNUMA） vs 分布式
- 互连：总线 / Crossbar / Fat Tree / Mesh / Torus
- 系统：MPP / Cluster / GPU / Vector
